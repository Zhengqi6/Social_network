"""
Recommendation System Main Program
æ•´åˆæ•°æ®å¤„ç†å’Œæ¨èæ¨¡å‹
"""

import asyncio
import pandas as pd
import numpy as np
from typing import Dict, List, Any
import json
from datetime import datetime
from loguru import logger

# å¯¼å…¥æ•°æ®å¤„ç†æ¨¡å—
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_processing.process_pipeline import DataProcessingPipeline
from models.collaborative_filtering import CollaborativeFiltering


class RecommendationSystem:
    """æ¨èç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.data_pipeline = DataProcessingPipeline()
        self.models = {}
        self.processed_data = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨èç³»ç»Ÿ"""
        try:
            await self.data_pipeline.initialize()
            logger.info("Recommendation system initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize recommendation system: {e}")
            raise
    
    async def process_data(self):
        """å¤„ç†æ•°æ®"""
        try:
            logger.info("ğŸ”„ Processing data for recommendation system...")
            
            # è¿è¡Œæ•°æ®å¤„ç†ç®¡é“
            self.processed_data = await self.data_pipeline.run_full_pipeline()
            
            logger.info("âœ… Data processing completed")
            return self.processed_data
            
        except Exception as e:
            logger.error(f"Error processing data: {e}")
            raise
    
    def create_interaction_matrix(self) -> pd.DataFrame:
        """åˆ›å»ºç”¨æˆ·-å¸–å­äº¤äº’çŸ©é˜µ"""
        try:
            if not self.processed_data:
                raise ValueError("No processed data available")
            
            # ä»Neo4jå…³ç³»æ•°æ®åˆ›å»ºäº¤äº’çŸ©é˜µ
            relationships = self.processed_data.get("raw_data", {}).get("neo4j", {}).get("relationships", pd.DataFrame())
            
            if relationships.empty:
                logger.warning("No relationship data available")
                return pd.DataFrame()
            
            # åˆ›å»ºäº¤äº’æ•°æ®
            interaction_data = []
            
            # å¤„ç†POSTEDå…³ç³»
            posted_rels = relationships[relationships['relationship_type'] == 'POSTED']
            for _, rel in posted_rels.iterrows():
                source_props = rel['source_props']
                target_props = rel['target_props']
                
                if 'profile_id' in source_props and 'post_id' in target_props:
                    interaction_data.append({
                        'user_id': source_props['profile_id'],
                        'post_id': target_props['post_id'],
                        'interaction': 1,  # å‘å¸–å…³ç³»
                        'type': 'POSTED'
                    })
            
            # å¤„ç†INTERACTEDå…³ç³»
            interacted_rels = relationships[relationships['relationship_type'] == 'INTERACTED']
            for _, rel in interacted_rels.iterrows():
                source_props = rel['source_props']
                target_props = rel['target_props']
                
                if 'profile_id' in source_props and 'post_id' in target_props:
                    interaction_data.append({
                        'user_id': source_props['profile_id'],
                        'post_id': target_props['post_id'],
                        'interaction': 1,  # äº’åŠ¨å…³ç³»
                        'type': 'INTERACTED'
                    })
            
            if not interaction_data:
                logger.warning("No interaction data created")
                return pd.DataFrame()
            
            # åˆ›å»ºDataFrame
            interaction_df = pd.DataFrame(interaction_data)
            
            # å»é‡å¹¶èšåˆ
            interaction_df = interaction_df.groupby(['user_id', 'post_id']).agg({
                'interaction': 'sum',
                'type': lambda x: ','.join(x.unique())
            }).reset_index()
            
            logger.info(f"Created interaction matrix with {len(interaction_df)} interactions")
            return interaction_df
            
        except Exception as e:
            logger.error(f"Error creating interaction matrix: {e}")
            return pd.DataFrame()
    
    def train_models(self, interaction_matrix: pd.DataFrame):
        """è®­ç»ƒæ¨èæ¨¡å‹"""
        try:
            if interaction_matrix.empty:
                logger.warning("No interaction data for training models")
                return
            
            logger.info("ğŸš€ Training recommendation models...")
            
            # è®­ç»ƒåŸºäºç”¨æˆ·çš„ååŒè¿‡æ»¤æ¨¡å‹
            user_based_model = CollaborativeFiltering(method="user_based")
            user_based_model.fit(interaction_matrix)
            self.models["user_based"] = user_based_model
            
            # è®­ç»ƒåŸºäºç‰©å“çš„ååŒè¿‡æ»¤æ¨¡å‹
            item_based_model = CollaborativeFiltering(method="item_based")
            item_based_model.fit(interaction_matrix)
            self.models["item_based"] = item_based_model
            
            # è®­ç»ƒçŸ©é˜µåˆ†è§£æ¨¡å‹
            matrix_factorization_model = CollaborativeFiltering(method="matrix_factorization")
            matrix_factorization_model.fit(interaction_matrix)
            self.models["matrix_factorization"] = matrix_factorization_model
            
            logger.info(f"âœ… Trained {len(self.models)} models successfully")
            
        except Exception as e:
            logger.error(f"Error training models: {e}")
            raise
    
    def get_recommendations(self, user_id: str, method: str = "user_based", n_recommendations: int = 5) -> List[Dict]:
        """è·å–æ¨èç»“æœ"""
        try:
            if method not in self.models:
                raise ValueError(f"Model {method} not trained")
            
            model = self.models[method]
            recommendations = model.recommend_for_user(user_id, n_recommendations)
            
            logger.info(f"Generated {len(recommendations)} recommendations for user {user_id} using {method}")
            return recommendations
            
        except Exception as e:
            logger.error(f"Error getting recommendations: {e}")
            return []
    
    def evaluate_models(self) -> Dict[str, Any]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        try:
            if not self.models:
                return {"error": "No models trained"}
            
            evaluation_results = {}
            
            for method, model in self.models.items():
                model_info = model.get_model_info()
                evaluation_results[method] = model_info
            
            logger.info("Model evaluation completed")
            return evaluation_results
            
        except Exception as e:
            logger.error(f"Error evaluating models: {e}")
            return {"error": str(e)}
    
    def save_recommendations(self, user_id: str, recommendations: List[Dict], output_dir: str = "./recommendations"):
        """ä¿å­˜æ¨èç»“æœ"""
        try:
            import os
            os.makedirs(output_dir, exist_ok=True)
            
            # åˆ›å»ºæ¨èç»“æœ
            result = {
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "recommendations": recommendations,
                "total_recommendations": len(recommendations)
            }
            
            # ä¿å­˜ä¸ºJSONæ–‡ä»¶
            output_path = f"{output_dir}/recommendations_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(output_path, 'w') as f:
                json.dump(result, f, indent=2, default=str)
            
            logger.info(f"Saved recommendations to {output_path}")
            
        except Exception as e:
            logger.error(f"Error saving recommendations: {e}")
    
    def close(self):
        """å…³é—­æ¨èç³»ç»Ÿ"""
        if self.data_pipeline:
            self.data_pipeline.close()


async def main():
    """ä¸»ç¨‹åº"""
    try:
        logger.info("ğŸš€ Starting Recommendation System...")
        
        # åˆå§‹åŒ–æ¨èç³»ç»Ÿ
        rec_system = RecommendationSystem()
        await rec_system.initialize()
        
        # å¤„ç†æ•°æ®
        await rec_system.process_data()
        
        # åˆ›å»ºäº¤äº’çŸ©é˜µ
        interaction_matrix = rec_system.create_interaction_matrix()
        
        if interaction_matrix.empty:
            logger.error("No interaction data available for training models")
            return
        
        # è®­ç»ƒæ¨¡å‹
        rec_system.train_models(interaction_matrix)
        
        # è¯„ä¼°æ¨¡å‹
        evaluation = rec_system.evaluate_models()
        print("\n" + "="*50)
        print("ğŸ“Š MODEL EVALUATION RESULTS")
        print("="*50)
        for method, info in evaluation.items():
            print(f"ğŸ”§ {method.upper()}:")
            for key, value in info.items():
                print(f"   {key}: {value}")
        
        # ä¸ºå‡ ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è
        unique_users = interaction_matrix['user_id'].unique()[:3]  # å–å‰3ä¸ªç”¨æˆ·
        
        print("\n" + "="*50)
        print("ğŸ¯ RECOMMENDATION RESULTS")
        print("="*50)
        
        for user_id in unique_users:
            print(f"\nğŸ‘¤ User: {user_id}")
            
            # ä½¿ç”¨ä¸åŒæ–¹æ³•ç”Ÿæˆæ¨è
            for method in ["user_based", "item_based", "matrix_factorization"]:
                recommendations = rec_system.get_recommendations(user_id, method, n_recommendations=3)
                
                print(f"   ğŸ“‹ {method.upper()} Recommendations:")
                for i, rec in enumerate(recommendations, 1):
                    print(f"      {i}. {rec['post_id']} (Score: {rec['score']:.4f})")
                
                # ä¿å­˜æ¨èç»“æœ
                rec_system.save_recommendations(user_id, recommendations)
        
        logger.info("ğŸ‰ Recommendation system completed successfully!")
        
    except Exception as e:
        logger.error(f"âŒ Recommendation system failed: {e}")
    finally:
        if 'rec_system' in locals():
            rec_system.close()


if __name__ == "__main__":
    asyncio.run(main())
